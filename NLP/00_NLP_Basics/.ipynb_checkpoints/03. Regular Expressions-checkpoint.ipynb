{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71f24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3073e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The quick brown fox jumps over the lazy dog!\"\n",
      "Isn't it a pangram? A pangram contains all the 26 letters of the English alphabet.\n",
      "I learned it from Sebastian, who is an English Teacher in Japan.\n",
      "His Phone: #9327404841\n",
      "Ooooh! I forgot his email. Hmmm, one sec! Gotcha\n",
      "His Email: seb.eng@sud.com\n",
      "I had begun his advanced English courses last month. I began to use many vocabularies.\n",
      "Behaviour? It's tooo good. You will like his behavior for sure!\n",
      "His is AMAAAZING\n",
      "U can begin his courses. U should email him too if u need to learn English and be fluent.\n",
      "www.sebastian.english.jp\n",
      "^^^Go to this website for a booking.\n"
     ]
    }
   ],
   "source": [
    "text = open('regEx.txt')\n",
    "txt = text.read()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefaffcc",
   "metadata": {},
   "source": [
    "#### Regular Expression Table\n",
    "\n",
    "\n",
    "| RegEx | Description | Matches |\n",
    "| --- | --- | --- |\n",
    "| [A-Z] | All uppercase letters | Finds the uppercase alphabets in the text |\n",
    "| [a-z] | All lowercase letters | Finds the lowercase alphabets in the text |\n",
    "| [A-Za-z] | All lowercase & uppercase letters | Finds the lower and uppercase alphabets in the text |\n",
    "| [Ss]ebastian | The exact combination or word with both uppercase and lowercase letter 'S/s' | Finds words: Sebastian, sebastian |\n",
    "| [^aeious] | Not the letters 'a,e,i,o,u,s' | Finds without the English vowels |\n",
    "| [^A-Z] | Not uppercase letters | Finds the Letters without uppercase alphabets |\n",
    "| [^0-9] | Not numerical digits | Finds the Letters without numerical digits |\n",
    "| [Bb]ehaviou?r | The letter is optional before the '?' sign | Finds both the word Behaviour/Behavior in US or UK English |\n",
    "| [AMA*ZING] | 0 or more occurances of the letter 'A' before the '*' sign | Finds the word AMAAAZING in the text |\n",
    "| [o+] | 1 or more occurances of the letter 'o' before the '+' sign | Finds the word Ooooh & too in the text |\n",
    "| [Hm{3}] | Exact number of occurances of a character in a word | Finds 'Hmmm' |\n",
    "| [beg.n] | Any letter between two characters | Finds: begin, begun\n",
    "| ^[A-Z] | Uppercase letters in the begining of the line | Finds: The, Isn't, His, etc. |\n",
    "| [A-Z]$ | Uppercase letters in the end of the line | Finds: AMAAAZING. |\n",
    "| '\\\\.' | All the periods in the text | Finds periods |\n",
    "| . | All the characters | Selects every character in the text |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c92bc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sebastian', 'sebastian']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\"[Ss]ebastian\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d552fbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'T', 'h', ' ', 'q', 'c', 'k', ' ', 'b', 'r', 'w', 'n', ' ', 'f', 'x', ' ', 'j', 'm', 'p', ' ', 'v', 'r', ' ', 't', 'h', ' ', 'l', 'z', 'y', ' ', 'd', 'g', '!', '\"', '\\n', 'n', \"'\", 't', ' ', 't', ' ', ' ', 'p', 'n', 'g', 'r', 'm', '?', ' ', ' ', 'p', 'n', 'g', 'r', 'm', ' ', 'c', 'n', 't', 'n', ' ', 'l', 'l', ' ', 't', 'h', ' ', '2', '6', ' ', 'l', 't', 't', 'r', ' ', 'f', ' ', 't', 'h', ' ', 'n', 'g', 'l', 'h', ' ', 'l', 'p', 'h', 'b', 't', '.', '\\n', ' ', 'l', 'r', 'n', 'd', ' ', 't', ' ', 'f', 'r', 'm', ' ', 'b', 't', 'n', ',', ' ', 'w', 'h', ' ', ' ', 'n', ' ', 'n', 'g', 'l', 'h', ' ', 'T', 'c', 'h', 'r', ' ', 'n', ' ', 'J', 'p', 'n', '.', '\\n', 'H', ' ', 'P', 'h', 'n', ':', ' ', '#', '9', '3', '2', '7', '4', '0', '4', '8', '4', '1', '\\n', 'h', '!', ' ', ' ', 'f', 'r', 'g', 't', ' ', 'h', ' ', 'm', 'l', '.', ' ', 'H', 'm', 'm', 'm', ',', ' ', 'n', ' ', 'c', '!', ' ', 'G', 't', 'c', 'h', '\\n', 'H', ' ', 'm', 'l', ':', ' ', 'b', '.', 'n', 'g', '@', 'd', '.', 'c', 'm', '\\n', ' ', 'h', 'd', ' ', 'b', 'g', 'n', ' ', 'h', ' ', 'd', 'v', 'n', 'c', 'd', ' ', 'n', 'g', 'l', 'h', ' ', 'c', 'r', ' ', 'l', 't', ' ', 'm', 'n', 't', 'h', '.', ' ', ' ', 'b', 'g', 'n', ' ', 't', ' ', ' ', 'm', 'n', 'y', ' ', 'v', 'c', 'b', 'l', 'r', '.', '\\n', 'B', 'h', 'v', 'r', '?', ' ', 't', \"'\", ' ', 't', ' ', 'g', 'd', '.', ' ', 'Y', ' ', 'w', 'l', 'l', ' ', 'l', 'k', ' ', 'h', ' ', 'b', 'h', 'v', 'r', ' ', 'f', 'r', ' ', 'r', '!', '\\n', 'H', ' ', ' ', 'M', 'Z', 'N', 'G', '\\n', ' ', 'c', 'n', ' ', 'b', 'g', 'n', ' ', 'h', ' ', 'c', 'r', '.', ' ', ' ', 'h', 'l', 'd', ' ', 'm', 'l', ' ', 'h', 'm', ' ', 't', ' ', 'f', ' ', ' ', 'n', 'd', ' ', 't', ' ', 'l', 'r', 'n', ' ', 'n', 'g', 'l', 'h', ' ', 'n', 'd', ' ', 'b', ' ', 'f', 'l', 'n', 't', '.', '\\n', 'w', 'w', 'w', '.', 'b', 't', 'n', '.', 'n', 'g', 'l', 'h', '.', 'j', 'p', '\\n', '^', '^', '^', 'G', ' ', 't', ' ', 't', 'h', ' ', 'w', 'b', 't', ' ', 'f', 'r', ' ', ' ', 'b', 'k', 'n', 'g', '.']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\"[^aeiousAEIOUS]\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36cc014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '6', '9', '3', '2', '7', '4', '0', '4', '8', '4', '1']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\"[0-9]\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deeb10c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26', '27']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\"[0-3][5-9]\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fa714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Behaviour', 'behavior']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\"[Bb]ehaviou?r\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "218ba369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMAAAZING']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\"AMA*ZING\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a96dce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row', 'fox', ' ov', 'dog', 'con', ' of', 'rom', 'ho ', 'hon', 'Ooooh', 'for', 'got', ' on', 'Got', 'com', 'cou', 'mon', 'to ', 'voc', 'iou', 'tooo ', 'good', 'You', 'ior', 'for', 'cou', 'hou', 'too ', 'to ', 'Go ', 'to ', 'for', 'book']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\".o+.\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4c6c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ooooh', 'tooo ']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\".o{3}.\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e24de89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['begun', 'began', 'begin']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\"beg.n\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7036d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'T', 'h', 'e', ' ', 'q', 'u', 'i', 'c', 'k', ' ', 'b', 'r', 'o', 'w', 'n', ' ', 'f', 'o', 'x', ' ', 'j', 'u', 'm', 'p', 's', ' ', 'o', 'v', 'e', 'r', ' ', 't', 'h', 'e', ' ', 'l', 'a', 'z', 'y', ' ', 'd', 'o', 'g', '!', '\"', 'I', 's', 'n', \"'\", 't', ' ', 'i', 't', ' ', 'a', ' ', 'p', 'a', 'n', 'g', 'r', 'a', 'm', '?', ' ', 'A', ' ', 'p', 'a', 'n', 'g', 'r', 'a', 'm', ' ', 'c', 'o', 'n', 't', 'a', 'i', 'n', 's', ' ', 'a', 'l', 'l', ' ', 't', 'h', 'e', ' ', '2', '6', ' ', 'l', 'e', 't', 't', 'e', 'r', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'a', 'l', 'p', 'h', 'a', 'b', 'e', 't', '.', 'I', ' ', 'l', 'e', 'a', 'r', 'n', 'e', 'd', ' ', 'i', 't', ' ', 'f', 'r', 'o', 'm', ' ', 'S', 'e', 'b', 'a', 's', 't', 'i', 'a', 'n', ',', ' ', 'w', 'h', 'o', ' ', 'i', 's', ' ', 'a', 'n', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'T', 'e', 'a', 'c', 'h', 'e', 'r', ' ', 'i', 'n', ' ', 'J', 'a', 'p', 'a', 'n', '.', 'H', 'i', 's', ' ', 'P', 'h', 'o', 'n', 'e', ':', ' ', '#', '9', '3', '2', '7', '4', '0', '4', '8', '4', '1', 'O', 'o', 'o', 'o', 'h', '!', ' ', 'I', ' ', 'f', 'o', 'r', 'g', 'o', 't', ' ', 'h', 'i', 's', ' ', 'e', 'm', 'a', 'i', 'l', '.', ' ', 'H', 'm', 'm', 'm', ',', ' ', 'o', 'n', 'e', ' ', 's', 'e', 'c', '!', ' ', 'G', 'o', 't', 'c', 'h', 'a', 'H', 'i', 's', ' ', 'E', 'm', 'a', 'i', 'l', ':', ' ', 's', 'e', 'b', '.', 'e', 'n', 'g', '@', 's', 'u', 'd', '.', 'c', 'o', 'm', 'I', ' ', 'h', 'a', 'd', ' ', 'b', 'e', 'g', 'u', 'n', ' ', 'h', 'i', 's', ' ', 'a', 'd', 'v', 'a', 'n', 'c', 'e', 'd', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'c', 'o', 'u', 'r', 's', 'e', 's', ' ', 'l', 'a', 's', 't', ' ', 'm', 'o', 'n', 't', 'h', '.', ' ', 'I', ' ', 'b', 'e', 'g', 'a', 'n', ' ', 't', 'o', ' ', 'u', 's', 'e', ' ', 'm', 'a', 'n', 'y', ' ', 'v', 'o', 'c', 'a', 'b', 'u', 'l', 'a', 'r', 'i', 'e', 's', '.', 'B', 'e', 'h', 'a', 'v', 'i', 'o', 'u', 'r', '?', ' ', 'I', 't', \"'\", 's', ' ', 't', 'o', 'o', 'o', ' ', 'g', 'o', 'o', 'd', '.', ' ', 'Y', 'o', 'u', ' ', 'w', 'i', 'l', 'l', ' ', 'l', 'i', 'k', 'e', ' ', 'h', 'i', 's', ' ', 'b', 'e', 'h', 'a', 'v', 'i', 'o', 'r', ' ', 'f', 'o', 'r', ' ', 's', 'u', 'r', 'e', '!', 'H', 'i', 's', ' ', 'i', 's', ' ', 'A', 'M', 'A', 'A', 'A', 'Z', 'I', 'N', 'G', 'U', ' ', 'c', 'a', 'n', ' ', 'b', 'e', 'g', 'i', 'n', ' ', 'h', 'i', 's', ' ', 'c', 'o', 'u', 'r', 's', 'e', 's', '.', ' ', 'U', ' ', 's', 'h', 'o', 'u', 'l', 'd', ' ', 'e', 'm', 'a', 'i', 'l', ' ', 'h', 'i', 'm', ' ', 't', 'o', 'o', ' ', 'i', 'f', ' ', 'u', ' ', 'n', 'e', 'e', 'd', ' ', 't', 'o', ' ', 'l', 'e', 'a', 'r', 'n', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'a', 'n', 'd', ' ', 'b', 'e', ' ', 'f', 'l', 'u', 'e', 'n', 't', '.', 'w', 'w', 'w', '.', 's', 'e', 'b', 'a', 's', 't', 'i', 'a', 'n', '.', 'e', 'n', 'g', 'l', 'i', 's', 'h', '.', 'j', 'p', '^', '^', '^', 'G', 'o', ' ', 't', 'o', ' ', 't', 'h', 'i', 's', ' ', 'w', 'e', 'b', 's', 'i', 't', 'e', ' ', 'f', 'o', 'r', ' ', 'a', ' ', 'b', 'o', 'o', 'k', 'i', 'n', 'g', '.']\n"
     ]
    }
   ],
   "source": [
    "x = re.findall(\".\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e875fa",
   "metadata": {},
   "source": [
    "#### Regular Expression Techniques\n",
    "\n",
    "**Pattern Identifiers**\n",
    "\n",
    "| Character | Description | Example | Match |\n",
    "| ---       | ---         | ---     | ---   |\n",
    "| \\\\d | A digit | ID_\\d\\d\\d | ID_159 |\n",
    "| \\\\w | Alphanumerics | \\w\\w-\\w\\w\\w | 3B-A_1 |\n",
    "| \\\\s | Whitespaces | D\\sU\\sN\\sE | D U N E | \n",
    "| \\\\D | A non-digit | \\D\\D-503 | FC-503 |\n",
    "| \\\\W | Non-alphanumerics | \\W\\W\\W\\W | +)(- |\n",
    "| \\\\S | Non-whitespaces | \\S\\S\\S\\S\\S | Marko |\n",
    "\n",
    "**Pattern Quantifiers**\n",
    "\n",
    "| Character | Description | Example | Match |\n",
    "| ---       | ---         | ---     | ---   |\n",
    "| + | Occurs 1 or more times | Version \\d+\\w\\d+\\w\\d | Version 10.04.1 |\n",
    "| {4} | Occurs exactly 4 times | \\D{4} | AbCd |\n",
    "| {3,5} | Occurs 3 to 5 times | \\w{3,5} | 1YC, 1A_C, 2B_C1 | \n",
    "| {2,} | Occurs 2 or more | \\D{2,} | Apollo, Toy, hOspITal |\n",
    "| * | Occurs 0 or more times | a\\*B\\*c\\*D\\* | aaBDDDD, DD, aBc |\n",
    "| ? | Once or none/Optional | Boys? | Boy, Boys |\n",
    "| \\$ | position at the ending of a line | dog$ | Matches \"the dog\" but not \"dog run\" |\n",
    "| \\^ | position at the beginning of a line | ^Start | Matches \"Start here\" but not \"We Start\" |\n",
    "| \\b | word boundary | \\b[A-Z] | Gives only the words that starts with uppercase letter |\n",
    "**Pipe Operator/OR statement/Piping**\n",
    "\n",
    "The pipe operator `|` is a specific operator to join (pipe) multiple RegEx pattern in between. This is very useful for long, complex, and sophisticated character patterns in text. For example:\n",
    "> Patterns for text with only lowercase letters or only uppercase alphanumeric letters\n",
    "<br> ```= r\"^[a-z]+$|^[A-Z0-9]+$\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79898275",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My phone number is 902-746-0151\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1194b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4667c92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(3, 8), match='phone'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64752f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_match = re.search(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6468604e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81d7b7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_match.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc9fdac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_match.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beba64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"My phone number is attached to a new phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30c73b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = re.search(pattern, text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4599d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.span() # it doesn't find the second match of 'phone' at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a09389e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = re.findall(pattern, text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2402f012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "035ca939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n",
      "(37, 42)\n"
     ]
    }
   ],
   "source": [
    "for match in re.finditer(pattern, text1):\n",
    "    print(match.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ba9ab",
   "metadata": {},
   "source": [
    "## NLP-related RegEx Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4fd2eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(19, 31), match='902-746-0151'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text0 = \"My phone number is 902-746-0151\"\n",
    "pattern0 = r'\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d'\n",
    "\n",
    "phone_no = re.search(pattern0, text0)\n",
    "phone_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c02ee860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'902-746-0151'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_no.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28ccc88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using quantifiers\n",
    "text1 = \"My phone number is 902-746-0151. Alan's phone number is 675-936-3455.\"\n",
    "pattern1 = r'\\d{3}-\\d{3}-\\d{4}'\n",
    "\n",
    "phone_no = re.findall(pattern1, text1)\n",
    "len(phone_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "524686e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902-746-0151\n",
      "675-936-3455\n"
     ]
    }
   ],
   "source": [
    "for match in re.finditer(pattern1, text1):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac3072fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = \"My phone number is 902-746-0151. Alan's phone number is 6759363455.\"\n",
    "pattern2 = r'\\d{3}-\\d{3}-\\d{4}|\\d{10}'\n",
    "\n",
    "phone_no = re.findall(pattern2, text2)\n",
    "len(phone_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ab7be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902-746-0151\n",
      "6759363455\n"
     ]
    }
   ],
   "source": [
    "for match in re.finditer(pattern2, text2):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75c23dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"My phone number is 902-746-0151. Alan's phone number is 6759363455. Romano's phone number is (432)-567-8890\"\n",
    "pattern3 = r'\\d{3}-\\d{3}-\\d{4}|\\d{10}|\\W*\\d{3}\\W*-\\d{3}-\\d{4}'\n",
    "\n",
    "phone_no = re.findall(pattern3, text3)\n",
    "len(phone_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "036e5faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 902-746-0151\n",
      "6759363455\n",
      " (432)-567-8890\n"
     ]
    }
   ],
   "source": [
    "for match in re.finditer(pattern3, text3):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "293f223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 902-746-0151\n",
      " 6759363455\n",
      " (432)-567-8890\n"
     ]
    }
   ],
   "source": [
    "generalized_pattern = r'\\W*\\d{3}\\W*-*\\d{3}-*\\d{4}'\n",
    "\n",
    "for match in re.finditer(generalized_pattern, text3):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f4300",
   "metadata": {},
   "source": [
    "**Grouping:**\n",
    "\n",
    "By using parenthesis `()`, you can group any set of RegEx operation. This grouping can help you identify specific group of characters as you need. For example:<br>\n",
    "> You want only the first 3 digit of a phone number. So you can add `()` between the first three digit as a group and retrieve the specific group by index. You can also group all digits in the similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be8b7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 digits of each number:\n",
      "902\n",
      "675\n",
      "432\n"
     ]
    }
   ],
   "source": [
    "group_pattern = r'\\W*(\\d{3})\\W*-*(\\d{3})-*(\\d{4})'\n",
    "\n",
    "print(\"First 3 digits of each number:\")\n",
    "for match in re.finditer(group_pattern, text3):\n",
    "    print(match.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c59fcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 4 digits of each number:\n",
      "0151\n",
      "3455\n",
      "8890\n"
     ]
    }
   ],
   "source": [
    "print(\"Last 4 digits of each number:\")\n",
    "for match in re.finditer(group_pattern, text3):\n",
    "    print(match.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d1f6fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Middle 3 digits of each number:\n",
      "746\n",
      "936\n",
      "567\n"
     ]
    }
   ],
   "source": [
    "print(\"Middle 3 digits of each number:\")\n",
    "for match in re.finditer(group_pattern, text3):\n",
    "    print(match.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ded372",
   "metadata": {},
   "source": [
    "## Task 01: Perform Different Pattern Identifications of the Text\n",
    "\n",
    "<br>\n",
    "\n",
    "`Hi! My name is Benjamin. Have you heard about me? Well...I'm a squire for Ser Allander of the A.S.T. in the 17th regiment. He is known as Allander the Slender (for his thin stature) around the regiment. His code is 309-AST-4677-#17 for the infantry. He got the ranking score of 78.3 out of 100 in the special branch. Quite a lad!!! Ain't it? But he's sooo skinny for such badges. I can't remember his chest size. Ugh, it might be...12+9=21 and you minus the girth by 2, and it's only 19! Hahaa. But he is a good lad—oh dang! S#!T, a good lieutenant, sorry! I admire him so much and I'll die for him on the battlefield if he commands.`\n",
    "\n",
    "Perform the below tasks by creating patterns for each:\n",
    "- Separate Punctuation\n",
    "- Handle arithmatic operations\n",
    "- Handle contractions as it is\n",
    "- Keep elipsis as separate token\n",
    "- Make a final list of tokens after applying each patterns and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05bc1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello. Have we met... never mind, I am Jonah.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c14c63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Matches:\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "ellipsis_pattern = r'[.]{3}'\n",
    "\n",
    "print(\"All Matches:\")\n",
    "for match in re.finditer(ellipsis_pattern, text):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0737f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Don't you've nothin' to do about them? You're very naive. I'd look into it. How've you survived so long? I'm gonna end it's time. You'll love'em. Do you've somethin' to say?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbe58531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Matches:\n",
      "n't\n",
      "'ve\n",
      "thin'\n",
      "'re\n",
      "'d\n",
      "'ve\n",
      "'m\n",
      "'s\n",
      "'ll\n",
      "'em\n",
      "'ve\n",
      "thin'\n"
     ]
    }
   ],
   "source": [
    "contraction_pattern = r\"[n]{1}\\b[\\'][a-z-A-Z]|\\'[A-Za-z]+|[thin']{5}\"\n",
    "\n",
    "print(\"All Matches:\")\n",
    "for match in re.finditer(contraction_pattern, text):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3a220b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"If you add .5 to 1, will it be 1.5 or .51? Again, 3+6=9. But 475.50-00.50=475.0 will be the answer. Why there's a fraction even if it's a .0 afterall? What about 10/2? Or 5*6? What's 3!, can you say? 90% Can solve this.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fdc8480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Matches:\n",
      "1.5\n",
      "475.50\n",
      "00.50\n",
      "475.0\n"
     ]
    }
   ],
   "source": [
    "arithmatic_pattern = r\"[\\d]+[.][\\d]{1,}\"\n",
    "\n",
    "print(\"All Matches:\")\n",
    "for match in re.finditer(arithmatic_pattern, text):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48da70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello! I am Kora (Koraszeski). I am from Polska <Poland> and am learning English [as a 2nd language]. Vladimir, a nice guy from Russia, asked me, 'Where are you from?' I don't know what he meant by that!? It's a bit bigger-ish of a sentence for me to get. Can—could you help me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afcd88ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Matches:\n",
      "!\n",
      "(\n",
      ")\n",
      ".\n",
      "<\n",
      ">\n",
      "[\n",
      "]\n",
      ".\n",
      ",\n",
      ",\n",
      ",\n",
      "'\n",
      "?\n",
      "'\n",
      "'\n",
      "!\n",
      "?\n",
      "'\n",
      "-\n",
      ".\n",
      "—\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "punctuiation_pattern = r\"[^\\s\\w]|[^\\w]$\"\n",
    "\n",
    "print(\"All Matches:\")\n",
    "for match in re.finditer(punctuiation_pattern, text):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7353b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Rubio Ceaser (Knight of the Romans) didn't have any family status. You're ready to know the rest of'em?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f7b6d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Matches:\n",
      "Rubio\n",
      "Ceaser\n",
      "Knight\n",
      "of\n",
      "the\n",
      "Romans\n",
      "didn\n",
      "t\n",
      "have\n",
      "any\n",
      "family\n",
      "status\n",
      "You\n",
      "re\n",
      "ready\n",
      "to\n",
      "know\n",
      "the\n",
      "rest\n",
      "of\n",
      "em\n"
     ]
    }
   ],
   "source": [
    "word_pattern = r\"[a-zA-Z]+\"\n",
    "\n",
    "print(\"All Matches:\")\n",
    "for match in re.finditer(word_pattern, text):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c33d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Regiment no 677AST and TY76 has same commander 1O1B.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cd95dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Matches:\n",
      "677AST\n",
      "TY76\n",
      "1O1B\n"
     ]
    }
   ],
   "source": [
    "alpha_pattern = r\"([A-Z0-9]{2,})\"\n",
    "\n",
    "print(\"All Matches:\")\n",
    "for match in re.finditer(alpha_pattern, text):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c30bd0fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mList\u001b[49m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    This function Tokenizes the text based on the below criteria:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    1. separate punctuation & brackets\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    4. keep ellispsis as a single token\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Pattern for elipsis\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    This function Tokenizes the text based on the below criteria:\n",
    "    1. separate punctuation & brackets\n",
    "    2. handle numeric & arithmatic ops\n",
    "    3. handle contracction\n",
    "    4. keep ellispsis as a single token\n",
    "    \"\"\"\n",
    "\n",
    "    # Pattern for elipsis\n",
    "    pattern_ellipsis = r\"[.]{3}\" # all dots that occurs exactly 3 times (...)\n",
    "\n",
    "    # Pattern for alphanumerics\n",
    "    pattern_alpha = r\"([A-Z0-9]{2,})\" # any alphanumerics\n",
    "\n",
    "    # Pattern for contraction\n",
    "    pattern_contraction = r\"[n]{1}\\b[\\'][a-z-A-Z]|\\'[A-Za-z]+|[thin']{5}\" # any combination of alphabets having contraction (') including ending contraction (nothin', somethin') [1]\n",
    "\n",
    "    # Pattern for numerical and arithmatic ops\n",
    "    pattern_arithmatic = r\"[\\d]*[.][\\d]{1,}|[\\d]+|[\\+\\-\\*\\/\\%\\!\\=]\" # any digits, fraction, arithmatic operations (+,=,*,/,%,!) [2]\n",
    "\n",
    "    # Pattern for words\n",
    "    pattern_words = r\"[a-zA-Z]+(?=n't)|[a-zA-Z]+\" # any alphabetic word combination [3]\n",
    "\n",
    "    # Pattern for punctuation and brackets\n",
    "    pattern_punctuation = r\"[.!?:,]\" # any punctuation and brackets\n",
    "\n",
    "    # Combining all pattern in order\n",
    "    all_pattern = re.compile(\n",
    "        f\"({pattern_ellipsis})|\"\n",
    "        f\"({pattern_contraction})|\"\n",
    "        f\"({pattern_arithmatic})|\"\n",
    "        f\"({pattern_alpha})|\"\n",
    "        f\"({pattern_words})|\"\n",
    "        f\"({pattern_punctuation})\"\n",
    "    )\n",
    "\n",
    "    # Tokenize by order\n",
    "    tokens = []\n",
    "    for match in all_pattern.findall(text):\n",
    "        token = next(filter(None, match), None) # Filters out empty strings\n",
    "        if token:\n",
    "            tokens.append(token.lower())\n",
    "            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efe6e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_str = \"Hi! It's Benjamin. Have you heard about me? Well...I'm a squire for Ser Allander of the A.S.T. in the 17th regiment. He is known as Allander the Slender (for his thin stature) around the regiment. His code is 309AST4677 for the infantry. He got the ranking score of 78.3 out of 100 in the special branch. Quite a lad!!! Ain't it? But he's sooo skinny for such badges. I can't remember his chest size. Ugh, it might be...12+9=21 and you minus the girth by 2, and it's only 19! Hahaa. But he is a good lad—oh dang! S#!T, a good lieutenant, sorry! I admire him so much and I'll die for him on the battlefield if he commands.\"\n",
    "print(tokenize(test_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec5135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens: List, stopwords: List = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    This function will remove stopwords.\n",
    "    \"\"\"\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "    \n",
    "    with open(\"stopwords.txt\", \"r\") as stop:\n",
    "        for line in stop:\n",
    "            stopword = line.strip()\n",
    "            stopwords.append(stopword)\n",
    "\n",
    "    non_sw_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        sw_flag = False\n",
    "        \n",
    "        for sw in stopwords:\n",
    "            if token.lower() == sw.lower():\n",
    "                sw_flag = True\n",
    "                break\n",
    "            \n",
    "        if not sw_flag:\n",
    "            non_sw_tokens.append(token)\n",
    "\n",
    "    return non_sw_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a94506",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(test_str)\n",
    "cleaned = remove_stopwords(tokens)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(tokens: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    This function will remove special characters.\n",
    "    \"\"\"\n",
    "    cleaned_tokens = []\n",
    "    \n",
    "    special_pattern = r\"[^a-zA-Z0-9\\.]\"\n",
    "    \n",
    "    for token in tokens:\n",
    "        cleaned_token = \"\"\n",
    "        \n",
    "        for c in token:\n",
    "            if not re.match(special_pattern, c):\n",
    "                cleaned_token += c\n",
    "                \n",
    "        if cleaned_token:\n",
    "            cleaned_tokens.append(cleaned_token)\n",
    "            \n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611bccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = remove_special_characters(cleaned)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12793abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c868d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c243f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP GPU",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
