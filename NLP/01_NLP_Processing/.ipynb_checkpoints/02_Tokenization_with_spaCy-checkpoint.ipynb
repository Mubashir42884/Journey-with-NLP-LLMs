{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0f97dd",
   "metadata": {},
   "source": [
    "# NLP Processing - Tokenization\n",
    "\n",
    "**Tokenization** is the process of breaking down a raw text into smaller units (tokens) for machines. These tokens can be words, subwords, or only characters to make text understandable for the machines.\n",
    "\n",
    "**The parts of Tokenization:**\n",
    "> **A Full Text:** A complete sentence of the text. <br>\n",
    "`\"I'm having a wedding party in my U.K. residence!\"` <br>\n",
    "> **Split on Whitespace:** Seperated tokens on whitespace only. <br>\n",
    "`[\"I'm] [having] [a] [wedding] [party] [in] [my] [U.K.] [residence!\"]` <br>\n",
    "> **Prefix:** Characters at the beginning of a text. <br>\n",
    "`[\"] [I'm] [having] [a] [wedding] [party] [in] [my] [U.K.] [residence!\"]` <br>\n",
    "> **Exceptions:** Handling special cases (e.g. contractions, punctuations) that needed seperate set of rules to create tokens. <br>\n",
    "`[\"] [I] ['m] [having] [a] [wedding] [party] [in] [my] [U.K.] [residence] [!\"]` <br>\n",
    "> **Suffix:** Characters at the ending of a text. <br> \n",
    "`[\"] [I] ['m] [having] [a] [wedding] [party] [in] [my] [U.K.] [residence] [!] [\"]` <br>\n",
    "> **Tokenized:** Complete tokenized form of a text. <br>\n",
    "`[\"] [I] ['m] [having] [a] [wedding] [party] [in] [my] [U.K.] [residence!] [\"]` <br><br>\n",
    "\n",
    "<img src=\"Tokenization_The Parts of Tokens.png\" width=80%></img>\n",
    "\n",
    "| Token Type | Description | Example |\n",
    "| --- | --- | --- |\n",
    "| **Prefix** | Characters at the beginning | `$ ( { ‟ |\n",
    "| **Suffix** | Characters at the ending | `km ) , . ! ?` |\n",
    "| **Infix** | Characters in between | `- — / ...` |\n",
    "| **Exceptions** | Special-case rules for splitting | `can't U.S.` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722a1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d54953",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9a9fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're in a hurry for work in U.K.!\n"
     ]
    }
   ],
   "source": [
    "mystring = \"You\\'re in a hurry for work in U.K.!\"\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e80326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You\n",
      "'re\n",
      "in\n",
      "a\n",
      "hurry\n",
      "for\n",
      "work\n",
      "in\n",
      "U.K.\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(mystring)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c758a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's have a user-based experience on the 1st demo of our site https://www.rhsp.com!\n"
     ]
    }
   ],
   "source": [
    "mystring2 = \"Let's have a user-based experience on the 1st demo of our site https://www.rhsp.com!\"\n",
    "print(mystring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d16097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let | 's | have | a | user | - | based | experience | on | the | 1st | demo | of | our | site | https://www.rhsp.com | ! | "
     ]
    }
   ],
   "source": [
    "doc = nlp(mystring2)\n",
    "for token in doc:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e478b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achilles confronts Paris about what Hector died for, Troy or honor?\n"
     ]
    }
   ],
   "source": [
    "mystring3 = \"Achilles confronts Paris about what Hector died for, Troy or honor?\"\n",
    "print(mystring3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b685d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris \t= Countries, cities, states\n",
      "Hector \t= People, including fictional\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(mystring3)\n",
    "# for named entities\n",
    "for entity in doc1.ents:\n",
    "    print(entity, \"\\t=\", spacy.explain(entity.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e532225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google               = ORG = Companies, agencies, institutions, etc.\n",
      "$300 million dollar  = MONEY = Monetary values, including unit\n",
      "Taiwan               = GPE = Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"Google is not investing $300 million dollar for Taiwan-based stratups\")\n",
    "\n",
    "for entity in doc2.ents:\n",
    "    print(f\"{entity.text:<20} = {entity.label_} = {spacy.explain(entity.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2083d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achilles confronts\n",
      "what\n",
      "Hector\n",
      "Troy\n",
      "honor\n"
     ]
    }
   ],
   "source": [
    "# noun chunks\n",
    "for chunk in doc1.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "597ec3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google\n",
      "$300 million dollar\n",
      "Taiwan-based stratups\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc2.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f0a92",
   "metadata": {},
   "source": [
    "#### Summerize spaCy Functions\n",
    "\n",
    "> `token.text()` --> Shows each token from the given text.<br>\n",
    "> `doc.ents` --> Seperates NER (Named Entitiy Recognition).`entity.label_` shows NER type.<br>\n",
    "> `spacy.explain()` --> Shows human-readable description for tags and labels. <br>\n",
    "> `doc.noun_chunks` --> Seperates base noun phrase words. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa1d194c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tesla's new Cybertruck demo shouldn't be on the streets of L.A.! The design isn't normal and takes a lot more space than anyother normal car on the streets. Yes, it's unique and fashionable, but you've to think about others too. This $2.5 billion investment is not only for autonomous, eco-friendly, and futuristic-style, but also for the betterment of the people around the big cities. People involves: drivers, pedestrians, service-worker, and also the passengers...\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_string = (\n",
    "    \"Tesla's new Cybertruck demo shouldn't be on the streets of L.A.! The design isn't normal and takes a lot more space \" \n",
    "    \"than anyother normal car on the streets. Yes, it's unique and fashionable, but you've to think about others too. This \"\n",
    "    \"$2.5 billion investment is not only for autonomous, eco-friendly, and futuristic-style, but also for the betterment of \"\n",
    "    \"the people around the big cities. People involves: drivers, pedestrians, service-worker, and also the passengers...\"\n",
    ")\n",
    "f_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b295113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla | 's | new | Cybertruck | demo | should | n't | be | on | the | streets | of | L.A. | ! | The | design | is | n't | normal | and | takes | a | lot | more | space | than | anyother | normal | car | on | the | streets | . | Yes | , | it | 's | unique | and | fashionable | , | but | you | 've | to | think | about | others | too | . | This | $ | 2.5 | billion | investment | is | not | only | for | autonomous | , | eco | - | friendly | , | and | futuristic | - | style | , | but | also | for | the | betterment | of | the | people | around | the | big | cities | . | People | involves | : | drivers | , | pedestrians | , | service | - | worker | , | and | also | the | passengers | ... | "
     ]
    }
   ],
   "source": [
    "doc = nlp(f_string)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6203390f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla           ORG      = Companies, agencies, institutions, etc.\n",
      "Cybertruck      PERSON   = People, including fictional\n",
      "L.A.            GPE      = Countries, cities, states\n",
      "$2.5 billion    MONEY    = Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text:<15} {entity.label_:<8} = {spacy.explain(entity.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b0e639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla's new Cybertruck demo\n",
      "the streets\n",
      "L.A.\n",
      "The design\n",
      "a lot more space\n",
      "anyother normal car\n",
      "the streets\n",
      "it\n",
      "you\n",
      "others\n",
      "This $2.5 billion investment\n",
      "the betterment\n",
      "the people\n",
      "the big cities\n",
      "People\n",
      "drivers\n",
      "pedestrians\n",
      "service-worker\n",
      "also the passengers\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP GPU",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
